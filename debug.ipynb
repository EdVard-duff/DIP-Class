{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import ForwardRef\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch._C import import_ir_module\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import os\n",
    "\n",
    "from resnet_4ch import resnet\n",
    "\n",
    "class Config(object):\n",
    "    pretrained_model_path = './pretrained_models'\n",
    "\n",
    "    backbone = 'resnet18'\n",
    "    class_num = 2\n",
    "    without_mask =  True\n",
    "    embed_size = 64 # 不确定\n",
    "    loss_pcl = 10\n",
    "\n",
    "opt = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_layers = int(opt.backbone.split('resnet')[-1]) #34\n",
    "backbone = resnet(resnet_layers,\n",
    "                        True,\n",
    "                        os.path.join(opt.pretrained_model_path, opt.backbone+'.pth'))\n",
    "# drop pool layer and fc layer, resnet34 layer4 output shape: b,512,8,8\n",
    "features = list(backbone.children())\n",
    "len(features)\n",
    "#features[6]\n",
    "#features[7]\n",
    "backbone = nn.Sequential(*features[:7])\n",
    "prediction_head = nn.Sequential(*features[7])\n",
    "\n",
    "img = torch.rand(4,3,256,256)\n",
    "tmp = backbone(img)\n",
    "tmp = prediction_head(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#a=nn.AvgPool1d\n",
    "\n",
    "features[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 16, 16])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer = nn.Conv2d(256,opt.embed_size,kernel_size=(1,1))\n",
    "x = torch.rand(4,256,16,16)\n",
    "x = embedding_layer(x)\n",
    "x.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16, 4, 16, 16])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 16, 16, 16])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 16])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = torch.rand(4,64,16,16)\n",
    "y = torch.zeros(size=(16,16,4,16,16))\n",
    "for i in range(16):\n",
    "    for j in range(16):\n",
    "        y[i,j,:,:,:] = torch.sum(x[:,:,i,j,None,None] * x,dim=1)/np.sqrt(opt.embed_size)\n",
    "\n",
    "y.shape       \n",
    "y = torch.sigmoid(y)\n",
    "y = y.permute(2,0,1,3,4)\n",
    "y.shape\n",
    "\n",
    "av = torch.sum(y,dim = (3,4\n",
    "))\n",
    "av.shape\n",
    "\n",
    " \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fb71fd9c3a8870bae8b470c3c4c52a9514a1276bbeb9ea5c4061a9c129ee4266"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
